"""
Ejemplo de Uso SIN Base de Datos
================================

Prueba el agente de WhatsApp sin necesidad de PostgreSQL.
"""

import asyncio
import logging
from agents.sub_agent_whatsApp.state import create_initial_state
from agents.sub_agent_whatsApp.config import config

# Configurar logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


async def test_classification():
    """Prueba la clasificaciÃ³n de intenciones."""
    from langchain_anthropic import ChatAnthropic
    from agents.sub_agent_whatsApp.config import SYSTEM_PROMPT_CLASSIFIER
    import json

    llm = ChatAnthropic(
        model=config.llm_model,
        temperature=config.classifier_temperature,
        max_tokens=config.classifier_max_tokens,
    )

    test_messages = [
        "Hola, quiero agendar una cita para maÃ±ana a las 2pm",
        "Â¿CuÃ¡nto cuestan las plantillas ortopÃ©dicas?",
        "Necesito cancelar mi cita del viernes",
        "Â¿A quÃ© hora abren?",
        "Me duele mucho el pie, es urgente",
        "Gracias por la atenciÃ³n",
    ]

    print("\n" + "=" * 70)
    print("PRUEBA DE CLASIFICACIÃ“N DE INTENCIONES")
    print("=" * 70 + "\n")

    for msg in test_messages:
        prompt = f"{SYSTEM_PROMPT_CLASSIFIER}\n\nMensaje del usuario: {msg}"

        try:
            response = await llm.ainvoke(prompt)
            content = response.content

            # Intentar parsear JSON
            try:
                # Buscar JSON en la respuesta
                start = content.find("{")
                end = content.rfind("}") + 1
                if start >= 0 and end > start:
                    json_str = content[start:end]
                    result = json.loads(json_str)
                    intent = result.get("intent", "desconocido")
                    confidence = result.get("confidence", 0)
                    print(f"ğŸ“© '{msg[:40]}...'")
                    print(f"   â†’ IntenciÃ³n: {intent} (confianza: {confidence})")
                    print()
            except json.JSONDecodeError:
                print(f"ğŸ“© '{msg[:40]}...'")
                print(f"   â†’ Respuesta: {content[:100]}...")
                print()

        except Exception as e:
            print(f"âŒ Error: {e}")

    print("=" * 70 + "\n")


async def test_response_generation():
    """Prueba la generaciÃ³n de respuestas."""
    from langchain_anthropic import ChatAnthropic
    from agents.sub_agent_whatsApp.config import SYSTEM_PROMPT_MAIN

    llm = ChatAnthropic(
        model=config.llm_model,
        temperature=config.llm_temperature,
        max_tokens=config.llm_max_tokens,
    )

    test_scenarios = [
        {
            "intent": "agendar",
            "message": "Quiero una cita para maÃ±ana",
            "context": "El paciente Juan PÃ©rez estÃ¡ preguntando por primera vez.",
        },
        {
            "intent": "consulta",
            "message": "Â¿CuÃ¡nto cuestan las plantillas?",
            "context": "Paciente nuevo interesado en plantillas ortopÃ©dicas.",
        },
        {
            "intent": "info",
            "message": "Â¿CuÃ¡l es su direcciÃ³n?",
            "context": "El paciente quiere visitar la clÃ­nica.",
        },
    ]

    print("\n" + "=" * 70)
    print("PRUEBA DE GENERACIÃ“N DE RESPUESTAS")
    print("=" * 70 + "\n")

    for scenario in test_scenarios:
        prompt = f"""{SYSTEM_PROMPT_MAIN}

Contexto: {scenario['context']}
IntenciÃ³n detectada: {scenario['intent']}

Mensaje del usuario: {scenario['message']}

Genera una respuesta apropiada:"""

        try:
            response = await llm.ainvoke(prompt)
            print(f"ğŸ“© Usuario: {scenario['message']}")
            print(f"ğŸ¯ IntenciÃ³n: {scenario['intent']}")
            print(f"ğŸ¤– Respuesta: {response.content}")
            print("-" * 50)
            print()

        except Exception as e:
            print(f"âŒ Error: {e}")

    print("=" * 70 + "\n")


async def test_embeddings():
    """Prueba el servicio de embeddings."""
    from agents.sub_agent_whatsApp.utils.embeddings import get_embeddings_service

    print("\n" + "=" * 70)
    print("PRUEBA DE EMBEDDINGS")
    print("=" * 70 + "\n")

    test_texts = [
        "Quiero agendar una cita",
        "Â¿CuÃ¡nto cuesta la consulta?",
        "Me duele el pie derecho",
    ]

    embeddings_service = get_embeddings_service()

    for text in test_texts:
        try:
            embedding = embeddings_service.embed_query(text)
            print(f"ğŸ“ Texto: '{text}'")
            print(f"   â†’ Dimensiones: {len(embedding)}")
            print(f"   â†’ Primeros 5 valores: {embedding[:5]}")
            print()
        except Exception as e:
            print(f"âŒ Error: {e}")

    print("=" * 70 + "\n")


async def test_state():
    """Prueba la creaciÃ³n de estado."""
    print("\n" + "=" * 70)
    print("PRUEBA DE ESTADO")
    print("=" * 70 + "\n")

    state = create_initial_state(
        conversation_id="test-123",
        contact_id=1,
        whatsapp_number="+523331234567",
        contact_name="Juan PÃ©rez",
        message="Hola, quiero una cita",
        patient_id=None,
    )

    print("âœ… Estado creado correctamente:")
    print(f"   - Conversation ID: {state['conversation_id']}")
    print(f"   - Contact ID: {state['contact_id']}")
    print(f"   - WhatsApp: {state['whatsapp_number']}")
    print(f"   - Nombre: {state['contact_name']}")
    print(f"   - Mensajes: {len(state.get('messages', []))}")
    print(f"   - Todos los campos: {list(state.keys())}")
    print()
    print("=" * 70 + "\n")


async def main():
    """Ejecuta todas las pruebas."""
    print("\n" + "ğŸš€" * 35)
    print("\n  PRUEBAS DEL SUB-AGENTE WHATSAPP (SIN BASE DE DATOS)")
    print("\n" + "ğŸš€" * 35 + "\n")

    # 1. Probar estado
    await test_state()

    # 2. Probar embeddings
    await test_embeddings()

    # 3. Probar clasificaciÃ³n (requiere API key de Anthropic)
    try:
        await test_classification()
    except Exception as e:
        print(f"âš ï¸ Error en clasificaciÃ³n (Â¿API key configurada?): {e}\n")

    # 4. Probar generaciÃ³n de respuestas
    try:
        await test_response_generation()
    except Exception as e:
        print(f"âš ï¸ Error en generaciÃ³n (Â¿API key configurada?): {e}\n")

    print("\n" + "âœ…" * 35)
    print("\n  Â¡PRUEBAS COMPLETADAS!")
    print("\n" + "âœ…" * 35 + "\n")


if __name__ == "__main__":
    asyncio.run(main())
